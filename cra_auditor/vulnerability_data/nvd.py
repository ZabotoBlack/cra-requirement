import hashlib
import json
import logging
import os
import threading
import time
from pathlib import Path

import requests

logger = logging.getLogger(__name__)


def _resolve_cache_base_dir() -> Path:
    """Resolve directory for persistent runtime cache files.

    Priority:
    1) CRA_DATA_DIR env var override
    2) /data in containerized Home Assistant add-on runtime
    3) local project data directory for development
    """
    env_dir = os.environ.get("CRA_DATA_DIR")
    if env_dir:
        return Path(env_dir)

    container_data = Path("/data")
    if container_data.exists() and container_data.is_dir():
        return container_data

    return Path(__file__).resolve().parents[1] / "data"


class NVDClient:
    BASE_URL = "https://services.nvd.nist.gov/rest/json"

    def __init__(self, api_key: str | None = None, cache_path: str | None = None, cache_ttl_seconds: int = 86400):
        self.api_key = api_key or os.environ.get("NVD_API_KEY")
        self.cache_ttl_seconds = cache_ttl_seconds
        self.session = requests.Session()
        self._last_request_ts = 0.0
        self._lock = threading.Lock()

        default_cache = _resolve_cache_base_dir() / "nvd_cache.json"
        self.cache_path = Path(cache_path) if cache_path else default_cache
        self.cache_path.parent.mkdir(parents=True, exist_ok=True)
        self._cache = self._load_cache()

    def _load_cache(self) -> dict:
        if not self.cache_path.exists():
            return {}
        try:
            return json.loads(self.cache_path.read_text(encoding="utf-8"))
        except Exception:
            logger.warning("Failed to load NVD cache, starting fresh.")
            return {}

    def _save_cache(self):
        try:
            self.cache_path.write_text(json.dumps(self._cache), encoding="utf-8")
        except Exception:
            logger.debug("Failed to persist NVD cache.", exc_info=True)

    def _headers(self) -> dict:
        headers = {"User-Agent": "cra-auditor/1.0"}
        if self.api_key:
            headers["apiKey"] = self.api_key
        return headers

    def _rate_limit_delay(self):
        # Without an API key, NVD is throttled much more aggressively.
        min_interval = 0.8 if self.api_key else 6.2
        elapsed = time.time() - self._last_request_ts
        if elapsed < min_interval:
            time.sleep(min_interval - elapsed)

    def _cache_key(self, endpoint: str, params: dict) -> str:
        payload = json.dumps({"endpoint": endpoint, "params": params}, sort_keys=True)
        return hashlib.sha256(payload.encode("utf-8")).hexdigest()

    def _request(self, endpoint: str, params: dict) -> dict | None:
        key = self._cache_key(endpoint, params)
        now = time.time()

        cached = self._cache.get(key)
        if cached and (now - cached.get("ts", 0)) < self.cache_ttl_seconds:
            return cached.get("data")

        with self._lock:
            self._rate_limit_delay()
            url = f"{self.BASE_URL}{endpoint}"
            try:
                resp = self.session.get(url, params=params, headers=self._headers(), timeout=20)
                self._last_request_ts = time.time()

                if resp.status_code == 429:
                    logger.warning("NVD rate limit encountered; retrying once.")
                    time.sleep(6.2)
                    resp = self.session.get(url, params=params, headers=self._headers(), timeout=20)
                    self._last_request_ts = time.time()

                resp.raise_for_status()
                data = resp.json()
            except Exception:
                logger.error("NVD request failed for %s", endpoint, exc_info=True)
                return None

        self._cache[key] = {"ts": now, "data": data}
        self._save_cache()
        return data

    def search_cpes(self, keyword: str, limit: int = 5) -> list[dict]:
        if not keyword:
            return []

        data = self._request("/cpes/2.0", {
            "keywordSearch": keyword,
            "resultsPerPage": max(1, min(limit, 50)),
        })
        if not data:
            return []

        products = []
        for item in data.get("products", []):
            cpe = item.get("cpe", {})
            if not cpe:
                continue
            title = ""
            titles = cpe.get("titles") or []
            if titles:
                title = titles[0].get("title", "")
            products.append({
                "cpe": cpe.get("cpeName"),
                "deprecated": cpe.get("deprecated", False),
                "title": title,
                "refs": cpe.get("refs", []),
            })

        return products

    def get_vendor_reference_url(self, cpe_string: str) -> str | None:
        if not cpe_string:
            return None
        data = self._request("/cpes/2.0", {"cpeMatchString": cpe_string, "resultsPerPage": 1})
        if not data:
            return None

        for item in data.get("products", []):
            refs = (item.get("cpe", {}) or {}).get("refs", [])
            for ref in refs:
                url = ref.get("ref")
                if url and url.startswith("http"):
                    return url
        return None

    def _extract_cvss(self, cve_obj: dict) -> tuple[float, str]:
        metrics = cve_obj.get("metrics", {}) or {}
        for key in ["cvssMetricV31", "cvssMetricV30", "cvssMetricV2"]:
            entries = metrics.get(key)
            if not entries:
                continue
            primary = entries[0]
            cvss_data = primary.get("cvssData", {})
            score = float(cvss_data.get("baseScore", 0.0) or 0.0)
            severity = cvss_data.get("baseSeverity") or primary.get("baseSeverity") or "UNKNOWN"
            return score, str(severity).upper()
        return 0.0, "UNKNOWN"

    def get_cves_for_cpe(self, cpe_string: str, min_cvss: float = 0.0, limit: int = 10) -> list[dict]:
        if not cpe_string:
            return []

        data = self._request("/cves/2.0", {
            "cpeName": cpe_string,
            "resultsPerPage": 2000,
        })
        if not data:
            return []

        results = []
        for item in data.get("vulnerabilities", []):
            cve = item.get("cve", {})
            cve_id = cve.get("id")
            if not cve_id:
                continue

            score, severity = self._extract_cvss(cve)
            if score < min_cvss:
                continue

            description = "No description"
            for desc in cve.get("descriptions", []):
                if desc.get("lang") == "en":
                    description = desc.get("value", description)
                    break

            results.append({
                "id": cve_id,
                "severity": severity,
                "score": score,
                "description": (description[:200] + "...") if len(description) > 200 else description,
            })

        results.sort(key=lambda x: x.get("score", 0.0), reverse=True)
        return results[:max(1, limit)]
